{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9da01ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 29 04:39:32 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          On  |   00000000:18:00.0 Off |                    0 |\n",
      "| N/A   34C    P0            101W /  700W |       1MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "400ec4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/*\r\n"
     ]
    }
   ],
   "source": [
    "!echo ./datasets/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a35a394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGELOG.md  dotah_generator\t    models\t\t      trainers\r\n",
      "cmd.lnk       etc\t\t    output_models\t      train.py\r\n",
      "config.py     generate_data.bat     __pycache__\t\t      train_rcan.bat\r\n",
      "configs       Instructions.docx     raw_data\t\t      utils\r\n",
      "data\t      KJRD_net_train.ipynb  ReadMe.md\r\n",
      "data_source   mae\t\t    requirements_windows.yml\r\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf4363db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                  Version\r\n",
      "------------------------ -----------\r\n",
      "absl-py                  2.2.2\r\n",
      "accelerate               1.6.0\r\n",
      "aiohappyeyeballs         2.6.1\r\n",
      "aiohttp                  3.11.14\r\n",
      "aiosignal                1.3.2\r\n",
      "annotated-types          0.7.0\r\n",
      "asttokens                3.0.0\r\n",
      "async-timeout            5.0.1\r\n",
      "attrs                    25.3.0\r\n",
      "beautifulsoup4           4.13.4\r\n",
      "certifi                  2025.4.26\r\n",
      "charset-normalizer       3.4.1\r\n",
      "comm                     0.2.2\r\n",
      "contourpy                1.3.2\r\n",
      "cycler                   0.12.1\r\n",
      "dacite                   1.9.2\r\n",
      "datasets                 3.5.0\r\n",
      "debugpy                  1.8.14\r\n",
      "decorator                5.2.1\r\n",
      "dill                     0.3.8\r\n",
      "evaluate                 0.4.3\r\n",
      "exceptiongroup           1.2.2\r\n",
      "executing                2.2.0\r\n",
      "filelock                 3.18.0\r\n",
      "fonttools                4.57.0\r\n",
      "frozenlist               1.5.0\r\n",
      "fsspec                   2024.12.0\r\n",
      "gdown                    5.2.0\r\n",
      "grad-cam                 1.5.5\r\n",
      "h5py                     3.13.0\r\n",
      "htmlmin                  0.1.12\r\n",
      "huggingface-hub          0.30.2\r\n",
      "idna                     3.10\r\n",
      "ImageHash                4.3.1\r\n",
      "ipykernel                6.29.5\r\n",
      "ipython                  8.36.0\r\n",
      "ipywidgets               8.1.5\r\n",
      "jedi                     0.19.2\r\n",
      "Jinja2                   3.1.6\r\n",
      "joblib                   1.4.2\r\n",
      "jupyter_client           8.6.3\r\n",
      "jupyter_core             5.7.2\r\n",
      "jupyterlab_widgets       3.0.13\r\n",
      "keras                    3.7.0\r\n",
      "kiwisolver               1.4.8\r\n",
      "llvmlite                 0.44.0\r\n",
      "markdown-it-py           3.0.0\r\n",
      "MarkupSafe               3.0.2\r\n",
      "matplotlib               3.10.1\r\n",
      "matplotlib-inline        0.1.7\r\n",
      "mdurl                    0.1.2\r\n",
      "ml_dtypes                0.5.1\r\n",
      "mpmath                   1.3.0\r\n",
      "multidict                6.2.0\r\n",
      "multimethod              1.12\r\n",
      "multiprocess             0.70.16\r\n",
      "namex                    0.0.9\r\n",
      "nest-asyncio             1.6.0\r\n",
      "networkx                 3.4.2\r\n",
      "numba                    0.61.0\r\n",
      "numpy                    1.26.4\r\n",
      "nvidia-cublas-cu12       12.4.5.8\r\n",
      "nvidia-cuda-cupti-cu12   12.4.127\r\n",
      "nvidia-cuda-nvrtc-cu12   12.4.127\r\n",
      "nvidia-cuda-runtime-cu12 12.4.127\r\n",
      "nvidia-cudnn-cu12        9.1.0.70\r\n",
      "nvidia-cufft-cu12        11.2.1.3\r\n",
      "nvidia-curand-cu12       10.3.5.147\r\n",
      "nvidia-cusolver-cu12     11.6.1.9\r\n",
      "nvidia-cusparse-cu12     12.3.1.170\r\n",
      "nvidia-cusparselt-cu12   0.6.2\r\n",
      "nvidia-nccl-cu12         2.21.5\r\n",
      "nvidia-nvjitlink-cu12    12.4.127\r\n",
      "nvidia-nvtx-cu12         12.4.127\r\n",
      "opencv-python            4.10.0.84\r\n",
      "optree                   0.15.0\r\n",
      "packaging                25.0\r\n",
      "pandas                   2.2.3\r\n",
      "pandas-profiling         3.6.6\r\n",
      "parso                    0.8.4\r\n",
      "patsy                    1.0.1\r\n",
      "pexpect                  4.9.0\r\n",
      "phik                     0.12.4\r\n",
      "pillow                   11.2.1\r\n",
      "pip                      24.2\r\n",
      "platformdirs             4.3.7\r\n",
      "prompt_toolkit           3.0.51\r\n",
      "propcache                0.3.1\r\n",
      "psutil                   7.0.0\r\n",
      "ptyprocess               0.7.0\r\n",
      "pure_eval                0.2.3\r\n",
      "puremagic                1.28\r\n",
      "py-cpuinfo               9.0.0\r\n",
      "pyarrow                  19.0.1\r\n",
      "pydantic                 2.10.6\r\n",
      "pydantic_core            2.27.2\r\n",
      "Pygments                 2.19.1\r\n",
      "pyparsing                3.2.3\r\n",
      "PySocks                  1.7.1\r\n",
      "python-dateutil          2.9.0.post0\r\n",
      "pytz                     2025.2\r\n",
      "PyWavelets               1.8.0\r\n",
      "PyYAML                   6.0.2\r\n",
      "pyzmq                    26.4.0\r\n",
      "regex                    2024.11.6\r\n",
      "requests                 2.32.3\r\n",
      "rich                     14.0.0\r\n",
      "safetensors              0.5.3\r\n",
      "scikit-learn             1.6.1\r\n",
      "scipy                    1.15.2\r\n",
      "seaborn                  0.13.2\r\n",
      "setuptools               75.8.0\r\n",
      "six                      1.17.0\r\n",
      "soupsieve                2.7\r\n",
      "stack-data               0.6.3\r\n",
      "statsmodels              0.14.4\r\n",
      "sympy                    1.13.1\r\n",
      "threadpoolctl            3.6.0\r\n",
      "tokenizers               0.21.1\r\n",
      "torch                    2.6.0\r\n",
      "torchvision              0.21.0\r\n",
      "tornado                  6.4.2\r\n",
      "tqdm                     4.67.1\r\n",
      "traitlets                5.14.3\r\n",
      "transformers             4.51.3\r\n",
      "triton                   3.2.0\r\n",
      "ttach                    0.0.3\r\n",
      "typeguard                4.4.2\r\n",
      "typing_extensions        4.12.2\r\n",
      "tzdata                   2025.2\r\n",
      "ultralytics              8.3.80\r\n",
      "ultralytics-thop         2.0.14\r\n",
      "urllib3                  2.4.0\r\n",
      "visions                  0.8.1\r\n",
      "wcwidth                  0.2.13\r\n",
      "wheel                    0.44.0\r\n",
      "widgetsnbextension       4.0.13\r\n",
      "wordcloud                1.9.4\r\n",
      "xxhash                   3.5.0\r\n",
      "yarl                     1.18.3\r\n",
      "ydata-profiling          4.16.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7e56d6",
   "metadata": {},
   "source": [
    "### Generate Synthetic Hazy Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e197c111",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing validation set\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 458 out of 458 | elapsed:    5.1s finished\n"
     ]
    }
   ],
   "source": [
    "!python ./dotah_generator/dotah_v2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edbc387",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c154c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/hice1/wchia7/scratch/conda_venvs/DL_project/lib/python310.zip', '/home/hice1/wchia7/scratch/conda_venvs/DL_project/lib/python3.10', '/home/hice1/wchia7/scratch/conda_venvs/DL_project/lib/python3.10/lib-dynload', '', '/home/hice1/wchia7/.local/lib/python3.10/site-packages', '/home/hice1/wchia7/scratch/conda_venvs/DL_project/lib/python3.10/site-packages', '/home/hice1/wchia7/scratch/conda_venvs/DL_project/lib/python3.10/site-packages/setuptools/_vendor', '/tmp/tmp8j6d3ir_', '/storage/ice1/6/5/wchia7/DL_group_project']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to sys.path\n",
    "project_root = os.path.abspath(\".\")   # or adjust if needed\n",
    "sys.path.append(project_root)\n",
    "    \n",
    "os.chdir(\"/storage/ice1/6/5/wchia7/DL_group_project/trainers\")\n",
    "os.chdir(\"/storage/ice1/6/5/wchia7/DL_group_project\")\n",
    "os.environ[\"PYTHONPATH\"] = project_root\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d636e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGELOG.md  dotah_generator\t    mae\t\t   ReadMe.md\r\n",
      "cmd.lnk       etc\t\t    metric.py\t   requirements_windows.yml\r\n",
      "config.py     generate_data.bat     models\t   trainers\r\n",
      "configs       Instructions.docx     output_models  train.py\r\n",
      "data\t      KJRD_net_eval.ipynb   __pycache__    train_rcan.bat\r\n",
      "data_source   KJRD_net_train.ipynb  raw_data\t   utils\r\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c25adc1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=['mask_token', 'decoder_pos_embed', 'decoder_embed.weight', 'decoder_embed.bias', 'decoder_blocks.0.norm1.weight', 'decoder_blocks.0.norm1.bias', 'decoder_blocks.0.attn.qkv.weight', 'decoder_blocks.0.attn.qkv.bias', 'decoder_blocks.0.attn.proj.weight', 'decoder_blocks.0.attn.proj.bias', 'decoder_blocks.0.norm2.weight', 'decoder_blocks.0.norm2.bias', 'decoder_blocks.0.mlp.fc1.weight', 'decoder_blocks.0.mlp.fc1.bias', 'decoder_blocks.0.mlp.fc2.weight', 'decoder_blocks.0.mlp.fc2.bias', 'decoder_blocks.1.norm1.weight', 'decoder_blocks.1.norm1.bias', 'decoder_blocks.1.attn.qkv.weight', 'decoder_blocks.1.attn.qkv.bias', 'decoder_blocks.1.attn.proj.weight', 'decoder_blocks.1.attn.proj.bias', 'decoder_blocks.1.norm2.weight', 'decoder_blocks.1.norm2.bias', 'decoder_blocks.1.mlp.fc1.weight', 'decoder_blocks.1.mlp.fc1.bias', 'decoder_blocks.1.mlp.fc2.weight', 'decoder_blocks.1.mlp.fc2.bias', 'decoder_blocks.2.norm1.weight', 'decoder_blocks.2.norm1.bias', 'decoder_blocks.2.attn.qkv.weight', 'decoder_blocks.2.attn.qkv.bias', 'decoder_blocks.2.attn.proj.weight', 'decoder_blocks.2.attn.proj.bias', 'decoder_blocks.2.norm2.weight', 'decoder_blocks.2.norm2.bias', 'decoder_blocks.2.mlp.fc1.weight', 'decoder_blocks.2.mlp.fc1.bias', 'decoder_blocks.2.mlp.fc2.weight', 'decoder_blocks.2.mlp.fc2.bias', 'decoder_blocks.3.norm1.weight', 'decoder_blocks.3.norm1.bias', 'decoder_blocks.3.attn.qkv.weight', 'decoder_blocks.3.attn.qkv.bias', 'decoder_blocks.3.attn.proj.weight', 'decoder_blocks.3.attn.proj.bias', 'decoder_blocks.3.norm2.weight', 'decoder_blocks.3.norm2.bias', 'decoder_blocks.3.mlp.fc1.weight', 'decoder_blocks.3.mlp.fc1.bias', 'decoder_blocks.3.mlp.fc2.weight', 'decoder_blocks.3.mlp.fc2.bias', 'decoder_blocks.4.norm1.weight', 'decoder_blocks.4.norm1.bias', 'decoder_blocks.4.attn.qkv.weight', 'decoder_blocks.4.attn.qkv.bias', 'decoder_blocks.4.attn.proj.weight', 'decoder_blocks.4.attn.proj.bias', 'decoder_blocks.4.norm2.weight', 'decoder_blocks.4.norm2.bias', 'decoder_blocks.4.mlp.fc1.weight', 'decoder_blocks.4.mlp.fc1.bias', 'decoder_blocks.4.mlp.fc2.weight', 'decoder_blocks.4.mlp.fc2.bias', 'decoder_blocks.5.norm1.weight', 'decoder_blocks.5.norm1.bias', 'decoder_blocks.5.attn.qkv.weight', 'decoder_blocks.5.attn.qkv.bias', 'decoder_blocks.5.attn.proj.weight', 'decoder_blocks.5.attn.proj.bias', 'decoder_blocks.5.norm2.weight', 'decoder_blocks.5.norm2.bias', 'decoder_blocks.5.mlp.fc1.weight', 'decoder_blocks.5.mlp.fc1.bias', 'decoder_blocks.5.mlp.fc2.weight', 'decoder_blocks.5.mlp.fc2.bias', 'decoder_blocks.6.norm1.weight', 'decoder_blocks.6.norm1.bias', 'decoder_blocks.6.attn.qkv.weight', 'decoder_blocks.6.attn.qkv.bias', 'decoder_blocks.6.attn.proj.weight', 'decoder_blocks.6.attn.proj.bias', 'decoder_blocks.6.norm2.weight', 'decoder_blocks.6.norm2.bias', 'decoder_blocks.6.mlp.fc1.weight', 'decoder_blocks.6.mlp.fc1.bias', 'decoder_blocks.6.mlp.fc2.weight', 'decoder_blocks.6.mlp.fc2.bias', 'decoder_blocks.7.norm1.weight', 'decoder_blocks.7.norm1.bias', 'decoder_blocks.7.attn.qkv.weight', 'decoder_blocks.7.attn.qkv.bias', 'decoder_blocks.7.attn.proj.weight', 'decoder_blocks.7.attn.proj.bias', 'decoder_blocks.7.norm2.weight', 'decoder_blocks.7.norm2.bias', 'decoder_blocks.7.mlp.fc1.weight', 'decoder_blocks.7.mlp.fc1.bias', 'decoder_blocks.7.mlp.fc2.weight', 'decoder_blocks.7.mlp.fc2.bias', 'decoder_norm.weight', 'decoder_norm.bias', 'decoder_pred.weight', 'decoder_pred.bias'], unexpected_keys=[])\n",
      "Running Inference:   0%|                                 | 0/30 [00:00<?, ?it/s]Inference batch: 0\n",
      "/storage/ice1/6/5/wchia7/DL_group_project/models/masked_autoencoder.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(img)\n",
      "Running Inference:   3%|▊                        | 1/30 [00:00<00:26,  1.08it/s]Inference batch: 1\n",
      "Running Inference:   7%|█▋                       | 2/30 [00:01<00:17,  1.63it/s]Inference batch: 2\n",
      "Running Inference:  10%|██▌                      | 3/30 [00:01<00:14,  1.86it/s]Inference batch: 3\n",
      "Running Inference:  13%|███▎                     | 4/30 [00:02<00:18,  1.38it/s]Inference batch: 4\n",
      "Running Inference:  17%|████▏                    | 5/30 [00:03<00:15,  1.58it/s]Inference batch: 5\n",
      "Running Inference:  20%|█████                    | 6/30 [00:03<00:13,  1.78it/s]Inference batch: 6\n",
      "Running Inference:  23%|█████▊                   | 7/30 [00:04<00:11,  1.93it/s]Inference batch: 7\n",
      "Running Inference:  27%|██████▋                  | 8/30 [00:04<00:10,  2.12it/s]Inference batch: 8\n",
      "Running Inference:  30%|███████▌                 | 9/30 [00:05<00:10,  1.97it/s]Inference batch: 9\n",
      "Running Inference:  33%|████████                | 10/30 [00:05<00:09,  2.16it/s]Inference batch: 10\n",
      "Running Inference:  37%|████████▊               | 11/30 [00:05<00:08,  2.32it/s]Inference batch: 11\n",
      "Running Inference:  40%|█████████▌              | 12/30 [00:06<00:07,  2.43it/s]Inference batch: 12\n",
      "Running Inference:  43%|██████████▍             | 13/30 [00:06<00:06,  2.44it/s]Inference batch: 13\n",
      "Running Inference:  47%|███████████▏            | 14/30 [00:06<00:06,  2.49it/s]Inference batch: 14\n",
      "Running Inference:  50%|████████████            | 15/30 [00:07<00:06,  2.32it/s]Inference batch: 15\n",
      "Running Inference:  53%|████████████▊           | 16/30 [00:07<00:05,  2.38it/s]Inference batch: 16\n",
      "Running Inference:  57%|█████████████▌          | 17/30 [00:08<00:05,  2.46it/s]Inference batch: 17\n",
      "Running Inference:  60%|██████████████▍         | 18/30 [00:08<00:04,  2.41it/s]Inference batch: 18\n",
      "Running Inference:  63%|███████████████▏        | 19/30 [00:09<00:04,  2.50it/s]Inference batch: 19\n",
      "Running Inference:  67%|████████████████        | 20/30 [00:09<00:04,  2.48it/s]Inference batch: 20\n",
      "Running Inference:  70%|████████████████▊       | 21/30 [00:09<00:03,  2.56it/s]Inference batch: 21\n",
      "Running Inference:  73%|█████████████████▌      | 22/30 [00:10<00:03,  2.35it/s]Inference batch: 22\n",
      "Running Inference:  77%|██████████████████▍     | 23/30 [00:10<00:02,  2.46it/s]Inference batch: 23\n",
      "Running Inference:  80%|███████████████████▏    | 24/30 [00:11<00:02,  2.20it/s]Inference batch: 24\n",
      "Running Inference:  83%|████████████████████    | 25/30 [00:11<00:02,  2.18it/s]Inference batch: 25\n",
      "Running Inference:  87%|████████████████████▊   | 26/30 [00:12<00:01,  2.25it/s]Inference batch: 26\n",
      "Running Inference:  90%|█████████████████████▌  | 27/30 [00:12<00:01,  2.37it/s]Inference batch: 27\n",
      "Running Inference:  93%|██████████████████████▍ | 28/30 [00:12<00:00,  2.44it/s]Inference batch: 28\n",
      "Running Inference:  97%|███████████████████████▏| 29/30 [00:13<00:00,  1.73it/s]Inference batch: 29\n",
      "Running Inference: 100%|████████████████████████| 30/30 [00:14<00:00,  2.11it/s]\n",
      "pred: tensor([319.6745, 511.9761, 512.0000, 512.0000]), gt: tensor([102, 132, 151, 185])\n",
      "pred_max: 512.0, gt_max185\n",
      "pred: tensor([470.5609, 263.1319, 511.7837, 311.3822]), gt: tensor([ 75,  66, 171, 141])\n",
      "pred_max: 511.78369140625, gt_max171\n",
      "pred: tensor([511.2931, 422.8823, 512.0000, 511.2990]), gt: tensor([ 61,  72, 162, 151])\n",
      "pred_max: 512.0, gt_max162\n",
      "pred: tensor([402.3898, 511.8884, 494.8767, 511.9992]), gt: tensor([219, 227, 223, 229])\n",
      "pred_max: 511.9991760253906, gt_max229\n",
      "Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python metric.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "265f0550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/ice1/6/5/wchia7/DL_group_project/raw_data/dota_hazed/val/labelTxts\r\n"
     ]
    }
   ],
   "source": [
    "!echo /storage/ice1/6/5/wchia7/DL_group_project/raw_data/dota_hazed/val/labelTxts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DL_project]",
   "language": "python",
   "name": "conda-env-DL_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
